{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection and Modeling\n",
    "\n",
    "- [Linear Regression: OLS](#lm)\n",
    "- [Lasso Regression](#lasso)\n",
    "- [Random Forest Regression](#rfr)\n",
    "- [Light Gradient Boosting Model With Bayesian Optimization](#lgbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Necessary Modules and Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tools to get datasets\n",
    "from zipfile import ZipFile\n",
    "import urllib\n",
    "import requests\n",
    "import io\n",
    "\n",
    "# Import modules for data reading and plots\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Import all for model selections and modelling\n",
    "from bayes_opt import BayesianOptimization\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# Timer\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time() # Timer starts\n",
    "\n",
    "Xtrainurl = 'https://github.com/jonahwinninghoff/Springboard_Capstone_Project/raw/main/Assets/X_train.zip'\n",
    "Xvalidurl = 'https://github.com/jonahwinninghoff/Springboard_Capstone_Project/raw/main/Assets/X_valid.zip'\n",
    "Xtestiurl = 'https://github.com/jonahwinninghoff/Springboard_Capstone_Project/raw/main/Assets/X_test.zip'\n",
    "\n",
    "ytrainurl = 'https://github.com/jonahwinninghoff/Springboard_Capstone_Project/blob/main/Assets/y_train?raw=true'\n",
    "yvalidurl = 'https://github.com/jonahwinninghoff/Springboard_Capstone_Project/blob/main/Assets/y_valid?raw=true'\n",
    "ytestiurl = 'https://github.com/jonahwinninghoff/Springboard_Capstone_Project/blob/main/Assets/y_test?raw=true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read X_train dataset\n",
    "url = urllib.request.urlopen(Xtrainurl)\n",
    "unzipfile = ZipFile(io.BytesIO(url.read()))\n",
    "file = unzipfile.open(\"X_train\")\n",
    "X_train = pd.read_csv(file, encoding='cp1252').drop('Unnamed: 0', \n",
    "                                                    axis=1)\n",
    "file.close()\n",
    "\n",
    "# Read X_valid dataset\n",
    "url = urllib.request.urlopen(Xvalidurl)\n",
    "unzipfile = ZipFile(io.BytesIO(url.read()))\n",
    "file = unzipfile.open(\"X_valid\")\n",
    "X_valid = pd.read_csv(file, encoding='cp1252').drop('Unnamed: 0', \n",
    "                                                    axis=1)\n",
    "file.close()\n",
    "\n",
    "# Read X_test dataset\n",
    "url = urllib.request.urlopen(Xtestiurl)\n",
    "unzipfile = ZipFile(io.BytesIO(url.read()))\n",
    "file = unzipfile.open(\"X_test\")\n",
    "X_test = pd.read_csv(file, encoding='cp1252').drop('Unnamed: 0', \n",
    "                                                    axis=1)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read y_train dataset\n",
    "response = requests.get(ytrainurl)\n",
    "response.raise_for_status()\n",
    "y_train = np.load(io.BytesIO(response.content))\n",
    "\n",
    "# Read y_valid dataset\n",
    "response = requests.get(yvalidurl)\n",
    "response.raise_for_status()\n",
    "y_valid = np.load(io.BytesIO(response.content))\n",
    "\n",
    "# Read y_test dataset\n",
    "response = requests.get(ytestiurl)\n",
    "response.raise_for_status()\n",
    "y_test = np.load(io.BytesIO(response.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read X_TFIDF_train\n",
    "url = urllib.request.urlopen('https://github.com/jonahwinninghoff/Springboard_Capstone_Project/blob/main/Assets/X_TFIDF_train.zip?raw=true')\n",
    "unzipfile = ZipFile(io.BytesIO(url.read()))\n",
    "file = unzipfile.open(\"X_TFIDF_train\")\n",
    "X_TFIDF_train = pd.read_csv(file, encoding='cp1252').drop('Unnamed: 0', \n",
    "                                                    axis=1)\n",
    "file.close()\n",
    "\n",
    "# Read X_TFIDF_valid\n",
    "url = urllib.request.urlopen('https://github.com/jonahwinninghoff/Springboard_Capstone_Project/blob/main/Assets/X_TFIDF_valid.zip?raw=true')\n",
    "unzipfile = ZipFile(io.BytesIO(url.read()))\n",
    "file = unzipfile.open(\"X_TFIDF_valid\")\n",
    "X_TFIDF_valid = pd.read_csv(file, encoding='cp1252').drop('Unnamed: 0', \n",
    "                                                    axis=1)\n",
    "file.close()\n",
    "\n",
    "# Read X_TFIDF_test\n",
    "url = urllib.request.urlopen('https://github.com/jonahwinninghoff/Springboard_Capstone_Project/blob/main/Assets/X_TFIDF_test.zip?raw=true')\n",
    "unzipfile = ZipFile(io.BytesIO(url.read()))\n",
    "file = unzipfile.open(\"X_TFIDF_test\")\n",
    "X_TFIDF_test = pd.read_csv(file, encoding='cp1252').drop('Unnamed: 0', \n",
    "                                                    axis=1)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>activities</th>\n",
       "      <th>antianxiety</th>\n",
       "      <th>antipsychotic</th>\n",
       "      <th>appropriately</th>\n",
       "      <th>assessed</th>\n",
       "      <th>bladder</th>\n",
       "      <th>bowels</th>\n",
       "      <th>catheter</th>\n",
       "      <th>control</th>\n",
       "      <th>...</th>\n",
       "      <th>risk</th>\n",
       "      <th>seasonal</th>\n",
       "      <th>short</th>\n",
       "      <th>symptoms</th>\n",
       "      <th>tract</th>\n",
       "      <th>ulcers</th>\n",
       "      <th>urinary</th>\n",
       "      <th>vaccine</th>\n",
       "      <th>weight</th>\n",
       "      <th>worsened</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.410134</td>\n",
       "      <td>0.410134</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.410134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.420905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.514482</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.414597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.516965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.384065</td>\n",
       "      <td>0.384065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.404843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.384065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ability  activities  antianxiety  antipsychotic  appropriately  assessed  \\\n",
       "0      0.0         0.0          0.0            0.0       0.410134  0.410134   \n",
       "1      0.0         0.0          0.0            0.0       0.000000  0.000000   \n",
       "2      0.0         0.0          0.0            0.0       0.000000  0.000000   \n",
       "3      0.0         0.0          0.0            0.0       0.384065  0.384065   \n",
       "4      0.0         0.0          0.0            0.0       0.000000  0.000000   \n",
       "\n",
       "    bladder  bowels  catheter  control  ...      risk  seasonal     short  \\\n",
       "0  0.000000     0.0  0.000000      0.0  ...  0.000000       0.0  0.000000   \n",
       "1  0.000000     0.0  0.000000      0.0  ...  0.420905       0.0  0.000000   \n",
       "2  0.414597     0.0  0.516965      0.0  ...  0.000000       0.0  0.000000   \n",
       "3  0.000000     0.0  0.000000      0.0  ...  0.000000       0.0  0.404843   \n",
       "4  0.000000     0.0  0.000000      0.0  ...  0.000000       0.0  0.000000   \n",
       "\n",
       "   symptoms  tract    ulcers  urinary   vaccine  weight  worsened  \n",
       "0       0.0    0.0  0.000000      0.0  0.410134     0.0       0.0  \n",
       "1       0.0    0.0  0.514482      0.0  0.000000     0.0       0.0  \n",
       "2       0.0    0.0  0.000000      0.0  0.000000     0.0       0.0  \n",
       "3       0.0    0.0  0.000000      0.0  0.384065     0.0       0.0  \n",
       "4       0.0    0.0  0.000000      0.0  0.000000     0.0       0.0  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_TFIDF_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pc_0</th>\n",
       "      <th>pc_1</th>\n",
       "      <th>pc_2</th>\n",
       "      <th>pc_3</th>\n",
       "      <th>pc_4</th>\n",
       "      <th>pc_5</th>\n",
       "      <th>pc_6</th>\n",
       "      <th>pc_7</th>\n",
       "      <th>pc_8</th>\n",
       "      <th>pc_9</th>\n",
       "      <th>...</th>\n",
       "      <th>pc_39</th>\n",
       "      <th>pc_40</th>\n",
       "      <th>pc_41</th>\n",
       "      <th>pc_42</th>\n",
       "      <th>pc_43</th>\n",
       "      <th>pc_44</th>\n",
       "      <th>pc_45</th>\n",
       "      <th>pc_46</th>\n",
       "      <th>pc_47</th>\n",
       "      <th>pc_48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.660904</td>\n",
       "      <td>0.020100</td>\n",
       "      <td>0.044738</td>\n",
       "      <td>0.026935</td>\n",
       "      <td>-0.086106</td>\n",
       "      <td>0.066239</td>\n",
       "      <td>-0.099660</td>\n",
       "      <td>0.012499</td>\n",
       "      <td>0.004524</td>\n",
       "      <td>0.011040</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.318443e-17</td>\n",
       "      <td>-5.534612e-17</td>\n",
       "      <td>5.331652e-17</td>\n",
       "      <td>4.521988e-17</td>\n",
       "      <td>2.701118e-17</td>\n",
       "      <td>3.721016e-17</td>\n",
       "      <td>3.798447e-17</td>\n",
       "      <td>-2.949072e-18</td>\n",
       "      <td>-5.659986e-18</td>\n",
       "      <td>-2.698157e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.230752</td>\n",
       "      <td>-0.269446</td>\n",
       "      <td>0.206676</td>\n",
       "      <td>-0.059364</td>\n",
       "      <td>0.588827</td>\n",
       "      <td>0.536291</td>\n",
       "      <td>-0.178171</td>\n",
       "      <td>-0.045429</td>\n",
       "      <td>-0.243858</td>\n",
       "      <td>-0.003194</td>\n",
       "      <td>...</td>\n",
       "      <td>1.706481e-17</td>\n",
       "      <td>4.385838e-17</td>\n",
       "      <td>9.343200e-17</td>\n",
       "      <td>-1.292393e-18</td>\n",
       "      <td>8.989491e-17</td>\n",
       "      <td>-1.310580e-16</td>\n",
       "      <td>-4.150333e-18</td>\n",
       "      <td>1.729439e-17</td>\n",
       "      <td>-2.413300e-17</td>\n",
       "      <td>-4.953298e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.209060</td>\n",
       "      <td>-0.212579</td>\n",
       "      <td>0.097886</td>\n",
       "      <td>-0.008835</td>\n",
       "      <td>0.004231</td>\n",
       "      <td>-0.063156</td>\n",
       "      <td>0.042141</td>\n",
       "      <td>0.035324</td>\n",
       "      <td>0.809934</td>\n",
       "      <td>0.002881</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.844634e-17</td>\n",
       "      <td>4.732783e-17</td>\n",
       "      <td>-9.565286e-17</td>\n",
       "      <td>-6.027299e-17</td>\n",
       "      <td>-6.189339e-17</td>\n",
       "      <td>6.670046e-17</td>\n",
       "      <td>-1.279662e-16</td>\n",
       "      <td>6.886053e-18</td>\n",
       "      <td>1.056147e-17</td>\n",
       "      <td>-1.085136e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.699247</td>\n",
       "      <td>0.077719</td>\n",
       "      <td>0.018114</td>\n",
       "      <td>-0.017220</td>\n",
       "      <td>0.047612</td>\n",
       "      <td>-0.035646</td>\n",
       "      <td>0.069493</td>\n",
       "      <td>-0.018699</td>\n",
       "      <td>-0.010775</td>\n",
       "      <td>-0.016971</td>\n",
       "      <td>...</td>\n",
       "      <td>4.330250e-17</td>\n",
       "      <td>4.234050e-17</td>\n",
       "      <td>4.527424e-18</td>\n",
       "      <td>-4.547363e-17</td>\n",
       "      <td>8.633957e-18</td>\n",
       "      <td>-1.006105e-17</td>\n",
       "      <td>-1.911232e-17</td>\n",
       "      <td>1.849295e-18</td>\n",
       "      <td>-8.714250e-18</td>\n",
       "      <td>7.712897e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.134388</td>\n",
       "      <td>-0.073403</td>\n",
       "      <td>-0.055115</td>\n",
       "      <td>0.002297</td>\n",
       "      <td>0.009668</td>\n",
       "      <td>-0.013379</td>\n",
       "      <td>-0.004968</td>\n",
       "      <td>0.018567</td>\n",
       "      <td>0.004221</td>\n",
       "      <td>0.028316</td>\n",
       "      <td>...</td>\n",
       "      <td>9.859681e-17</td>\n",
       "      <td>1.089863e-17</td>\n",
       "      <td>-7.657090e-17</td>\n",
       "      <td>-7.363926e-18</td>\n",
       "      <td>4.045529e-17</td>\n",
       "      <td>1.638450e-16</td>\n",
       "      <td>-1.925847e-16</td>\n",
       "      <td>-5.284049e-20</td>\n",
       "      <td>-6.785768e-18</td>\n",
       "      <td>-1.674942e-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pc_0      pc_1      pc_2      pc_3      pc_4      pc_5      pc_6  \\\n",
       "0  0.660904  0.020100  0.044738  0.026935 -0.086106  0.066239 -0.099660   \n",
       "1 -0.230752 -0.269446  0.206676 -0.059364  0.588827  0.536291 -0.178171   \n",
       "2 -0.209060 -0.212579  0.097886 -0.008835  0.004231 -0.063156  0.042141   \n",
       "3  0.699247  0.077719  0.018114 -0.017220  0.047612 -0.035646  0.069493   \n",
       "4 -0.134388 -0.073403 -0.055115  0.002297  0.009668 -0.013379 -0.004968   \n",
       "\n",
       "       pc_7      pc_8      pc_9  ...         pc_39         pc_40  \\\n",
       "0  0.012499  0.004524  0.011040  ... -1.318443e-17 -5.534612e-17   \n",
       "1 -0.045429 -0.243858 -0.003194  ...  1.706481e-17  4.385838e-17   \n",
       "2  0.035324  0.809934  0.002881  ... -3.844634e-17  4.732783e-17   \n",
       "3 -0.018699 -0.010775 -0.016971  ...  4.330250e-17  4.234050e-17   \n",
       "4  0.018567  0.004221  0.028316  ...  9.859681e-17  1.089863e-17   \n",
       "\n",
       "          pc_41         pc_42         pc_43         pc_44         pc_45  \\\n",
       "0  5.331652e-17  4.521988e-17  2.701118e-17  3.721016e-17  3.798447e-17   \n",
       "1  9.343200e-17 -1.292393e-18  8.989491e-17 -1.310580e-16 -4.150333e-18   \n",
       "2 -9.565286e-17 -6.027299e-17 -6.189339e-17  6.670046e-17 -1.279662e-16   \n",
       "3  4.527424e-18 -4.547363e-17  8.633957e-18 -1.006105e-17 -1.911232e-17   \n",
       "4 -7.657090e-17 -7.363926e-18  4.045529e-17  1.638450e-16 -1.925847e-16   \n",
       "\n",
       "          pc_46         pc_47         pc_48  \n",
       "0 -2.949072e-18 -5.659986e-18 -2.698157e-17  \n",
       "1  1.729439e-17 -2.413300e-17 -4.953298e-17  \n",
       "2  6.886053e-18  1.056147e-17 -1.085136e-16  \n",
       "3  1.849295e-18 -8.714250e-18  7.712897e-18  \n",
       "4 -5.284049e-20 -6.785768e-18 -1.674942e-16  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 141159 entries, 0 to 141158\n",
      "Data columns (total 49 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   ability        141159 non-null  float64\n",
      " 1   activities     141159 non-null  float64\n",
      " 2   antianxiety    141159 non-null  float64\n",
      " 3   antipsychotic  141159 non-null  float64\n",
      " 4   appropriately  141159 non-null  float64\n",
      " 5   assessed       141159 non-null  float64\n",
      " 6   bladder        141159 non-null  float64\n",
      " 7   bowels         141159 non-null  float64\n",
      " 8   catheter       141159 non-null  float64\n",
      " 9   control        141159 non-null  float64\n",
      " 10  daily          141159 non-null  float64\n",
      " 11  depressive     141159 non-null  float64\n",
      " 12  experiencing   141159 non-null  float64\n",
      " 13  falls          141159 non-null  float64\n",
      " 14  function       141159 non-null  float64\n",
      " 15  given          141159 non-null  float64\n",
      " 16  help           141159 non-null  float64\n",
      " 17  high           141159 non-null  float64\n",
      " 18  hypnotic       141159 non-null  float64\n",
      " 19  improvements   141159 non-null  float64\n",
      " 20  increased      141159 non-null  float64\n",
      " 21  independently  141159 non-null  float64\n",
      " 22  infection      141159 non-null  float64\n",
      " 23  influenza      141159 non-null  float64\n",
      " 24  injury         141159 non-null  float64\n",
      " 25  inserted       141159 non-null  float64\n",
      " 26  left           141159 non-null  float64\n",
      " 27  long           141159 non-null  float64\n",
      " 28  lose           141159 non-null  float64\n",
      " 29  low            141159 non-null  float64\n",
      " 30  major          141159 non-null  float64\n",
      " 31  medication     141159 non-null  float64\n",
      " 32  need           141159 non-null  float64\n",
      " 33  newly          141159 non-null  float64\n",
      " 34  physically     141159 non-null  float64\n",
      " 35  pneumococcal   141159 non-null  float64\n",
      " 36  pressure       141159 non-null  float64\n",
      " 37  received       141159 non-null  float64\n",
      " 38  restrained     141159 non-null  float64\n",
      " 39  risk           141159 non-null  float64\n",
      " 40  seasonal       141159 non-null  float64\n",
      " 41  short          141159 non-null  float64\n",
      " 42  symptoms       141159 non-null  float64\n",
      " 43  tract          141159 non-null  float64\n",
      " 44  ulcers         141159 non-null  float64\n",
      " 45  urinary        141159 non-null  float64\n",
      " 46  vaccine        141159 non-null  float64\n",
      " 47  weight         141159 non-null  float64\n",
      " 48  worsened       141159 non-null  float64\n",
      "dtypes: float64(49)\n",
      "memory usage: 52.8 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(X_TFIDF_train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(141159, 49)\n",
      "(141159, 49)\n"
     ]
    }
   ],
   "source": [
    "print(X_TFIDF_train.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression: OLS <a id ='lm'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonahwinninghoff/opt/anaconda3/lib/python3.8/site-packages/statsmodels/tsa/tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th>  <td>   0.909</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.909</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>8.341e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 15 Sep 2021</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:23:00</td>     <th>  Log-Likelihood:    </th> <td>1.1010e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>141159</td>      <th>  AIC:               </th> <td>-2.202e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>141141</td>      <th>  BIC:               </th> <td>-2.200e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    17</td>      <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>         <td>    6.1344</td> <td>    0.346</td> <td>   17.731</td> <td> 0.000</td> <td>    5.456</td> <td>    6.812</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ability</th>       <td>-2.687e+10</td> <td>  2.4e+10</td> <td>   -1.119</td> <td> 0.263</td> <td>-7.39e+10</td> <td> 2.02e+10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>activities</th>    <td>-5.969e+09</td> <td> 5.24e+10</td> <td>   -0.114</td> <td> 0.909</td> <td>-1.09e+11</td> <td> 9.68e+10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>antianxiety</th>   <td> 2.931e+10</td> <td>    3e+10</td> <td>    0.977</td> <td> 0.329</td> <td>-2.95e+10</td> <td> 8.81e+10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>antipsychotic</th> <td> 3.539e+10</td> <td> 3.57e+10</td> <td>    0.992</td> <td> 0.321</td> <td>-3.45e+10</td> <td> 1.05e+11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>appropriately</th> <td> -3.28e+10</td> <td> 2.19e+10</td> <td>   -1.496</td> <td> 0.135</td> <td>-7.58e+10</td> <td> 1.02e+10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>assessed</th>      <td>-2.656e+10</td> <td> 2.39e+10</td> <td>   -1.112</td> <td> 0.266</td> <td>-7.34e+10</td> <td> 2.02e+10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bladder</th>       <td>-1.863e+11</td> <td> 9.71e+10</td> <td>   -1.919</td> <td> 0.055</td> <td>-3.77e+11</td> <td>    4e+09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bowels</th>        <td>  1.28e+11</td> <td> 4.03e+10</td> <td>    3.177</td> <td> 0.001</td> <td>  4.9e+10</td> <td> 2.07e+11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>catheter</th>      <td> 2.363e+11</td> <td> 1.25e+11</td> <td>    1.888</td> <td> 0.059</td> <td>   -9e+09</td> <td> 4.82e+11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>control</th>       <td> 1.105e+11</td> <td>  4.3e+10</td> <td>    2.567</td> <td> 0.010</td> <td> 2.61e+10</td> <td> 1.95e+11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>daily</th>         <td> 1.695e+10</td> <td>  2.4e+10</td> <td>    0.705</td> <td> 0.481</td> <td>-3.02e+10</td> <td> 6.41e+10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>depressive</th>    <td>-3.816e+09</td> <td> 5.32e+10</td> <td>   -0.072</td> <td> 0.943</td> <td>-1.08e+11</td> <td>    1e+11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>experiencing</th>  <td> 1.003e+10</td> <td> 1.29e+11</td> <td>    0.078</td> <td> 0.938</td> <td>-2.43e+11</td> <td> 2.63e+11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>falls</th>         <td> 1.492e+10</td> <td> 1.33e+11</td> <td>    0.112</td> <td> 0.911</td> <td>-2.46e+11</td> <td> 2.76e+11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>function</th>      <td>-6.604e+09</td> <td>  2.6e+10</td> <td>   -0.254</td> <td> 0.799</td> <td>-5.76e+10</td> <td> 4.43e+10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>given</th>         <td> 1.794e+09</td> <td> 3.75e+10</td> <td>    0.048</td> <td> 0.962</td> <td>-7.17e+10</td> <td> 7.53e+10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>help</th>          <td>-8.142e+08</td> <td> 1.36e+10</td> <td>   -0.060</td> <td> 0.952</td> <td>-2.75e+10</td> <td> 2.59e+10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>high</th>          <td> 1.541e+10</td> <td>    2e+10</td> <td>    0.769</td> <td> 0.442</td> <td>-2.39e+10</td> <td> 5.47e+10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hypnotic</th>      <td> 1.279e+09</td> <td> 4.76e+10</td> <td>    0.027</td> <td> 0.979</td> <td> -9.2e+10</td> <td> 9.45e+10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>improvements</th>  <td> 1.276e+10</td> <td>  2.4e+10</td> <td>    0.531</td> <td> 0.595</td> <td>-3.43e+10</td> <td> 5.98e+10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>increased</th>     <td>-1.884e+09</td> <td> 1.38e+10</td> <td>   -0.136</td> <td> 0.892</td> <td> -2.9e+10</td> <td> 2.52e+10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>independently</th> <td> 1.602e+10</td> <td> 1.34e+10</td> <td>    1.194</td> <td> 0.232</td> <td>-1.03e+10</td> <td> 4.23e+10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>infection</th>     <td> 7.501e+09</td> <td> 1.28e+10</td> <td>    0.584</td> <td> 0.559</td> <td>-1.77e+10</td> <td> 3.27e+10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>influenza</th>     <td> 3.383e+10</td> <td> 3.85e+10</td> <td>    0.880</td> <td> 0.379</td> <td>-4.16e+10</td> <td> 1.09e+11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>injury</th>        <td>-9.985e+09</td> <td>  1.3e+11</td> <td>   -0.077</td> <td> 0.939</td> <td>-2.65e+11</td> <td> 2.45e+11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>inserted</th>      <td>-4.024e+10</td> <td> 2.74e+10</td> <td>   -1.467</td> <td> 0.142</td> <td> -9.4e+10</td> <td> 1.35e+10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>left</th>          <td>-4.056e+10</td> <td> 2.76e+10</td> <td>   -1.472</td> <td> 0.141</td> <td>-9.46e+10</td> <td> 1.35e+10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>long</th>          <td>-1.934e+10</td> <td> 3.52e+10</td> <td>   -0.550</td> <td> 0.582</td> <td>-8.83e+10</td> <td> 4.96e+10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lose</th>          <td>-4.741e+09</td> <td> 2.83e+10</td> <td>   -0.168</td> <td> 0.867</td> <td>-6.02e+10</td> <td> 5.07e+10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>low</th>           <td>-3.906e+10</td> <td> 3.46e+10</td> <td>   -1.129</td> <td> 0.259</td> <td>-1.07e+11</td> <td> 2.88e+10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>major</th>         <td> -8.66e+09</td> <td> 1.23e+11</td> <td>   -0.071</td> <td> 0.944</td> <td>-2.49e+11</td> <td> 2.32e+11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>medication</th>    <td>-1.634e+10</td> <td> 2.17e+10</td> <td>   -0.752</td> <td> 0.452</td> <td>-5.89e+10</td> <td> 2.62e+10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>need</th>          <td>-1.867e+09</td> <td> 1.38e+10</td> <td>   -0.135</td> <td> 0.892</td> <td>-2.89e+10</td> <td> 2.52e+10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>newly</th>         <td>   -2.1135</td> <td>    0.118</td> <td>  -17.986</td> <td> 0.000</td> <td>   -2.344</td> <td>   -1.883</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>physically</th>    <td> 7.543e+09</td> <td> 1.13e+10</td> <td>    0.670</td> <td> 0.503</td> <td>-1.45e+10</td> <td> 2.96e+10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pneumococcal</th>  <td> 5.273e+10</td> <td> 5.83e+10</td> <td>    0.904</td> <td> 0.366</td> <td>-6.16e+10</td> <td> 1.67e+11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pressure</th>      <td> 1.182e+10</td> <td>  1.4e+10</td> <td>    0.843</td> <td> 0.399</td> <td>-1.57e+10</td> <td> 3.93e+10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>received</th>      <td>-1.634e+10</td> <td> 2.17e+10</td> <td>   -0.752</td> <td> 0.452</td> <td>-5.89e+10</td> <td> 2.62e+10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>restrained</th>    <td>-3.595e+09</td> <td> 6.73e+09</td> <td>   -0.534</td> <td> 0.593</td> <td>-1.68e+10</td> <td>  9.6e+09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>risk</th>          <td>-3.994e+10</td> <td> 5.11e+10</td> <td>   -0.782</td> <td> 0.434</td> <td> -1.4e+11</td> <td> 6.02e+10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>seasonal</th>      <td> 1.891e+10</td> <td>    2e+10</td> <td>    0.946</td> <td> 0.344</td> <td>-2.03e+10</td> <td> 5.81e+10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>short</th>         <td>-9.652e+09</td> <td> 1.75e+10</td> <td>   -0.550</td> <td> 0.582</td> <td> -4.4e+10</td> <td> 2.47e+10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>symptoms</th>      <td> 9.838e+09</td> <td> 5.24e+10</td> <td>    0.188</td> <td> 0.851</td> <td>-9.29e+10</td> <td> 1.13e+11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tract</th>         <td>-6.534e+08</td> <td> 3.24e+09</td> <td>   -0.202</td> <td> 0.840</td> <td>   -7e+09</td> <td> 5.69e+09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ulcers</th>        <td> 1.182e+10</td> <td>  1.4e+10</td> <td>    0.843</td> <td> 0.399</td> <td>-1.57e+10</td> <td> 3.93e+10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>urinary</th>       <td>-6.534e+08</td> <td> 3.24e+09</td> <td>   -0.202</td> <td> 0.840</td> <td>   -7e+09</td> <td> 5.69e+09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>vaccine</th>       <td>-3.714e+08</td> <td> 4.01e+10</td> <td>   -0.009</td> <td> 0.993</td> <td> -7.9e+10</td> <td> 7.83e+10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weight</th>        <td> 1.026e+10</td> <td> 1.87e+10</td> <td>    0.549</td> <td> 0.583</td> <td>-2.64e+10</td> <td> 4.69e+10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>worsened</th>      <td> 1.724e+10</td> <td> 1.31e+10</td> <td>    1.317</td> <td> 0.188</td> <td>-8.42e+09</td> <td> 4.29e+10</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>39930.087</td> <th>  Durbin-Watson:     </th>  <td>   1.995</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>604268.632</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-0.952</td>   <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>12.956</td>   <th>  Cond. No.          </th>  <td>3.05e+16</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 1.72e-28. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.909\n",
       "Model:                            OLS   Adj. R-squared:                  0.909\n",
       "Method:                 Least Squares   F-statistic:                 8.341e+04\n",
       "Date:                Wed, 15 Sep 2021   Prob (F-statistic):               0.00\n",
       "Time:                        18:23:00   Log-Likelihood:             1.1010e+05\n",
       "No. Observations:              141159   AIC:                        -2.202e+05\n",
       "Df Residuals:                  141141   BIC:                        -2.200e+05\n",
       "Df Model:                          17                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=================================================================================\n",
       "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------\n",
       "const             6.1344      0.346     17.731      0.000       5.456       6.812\n",
       "ability       -2.687e+10    2.4e+10     -1.119      0.263   -7.39e+10    2.02e+10\n",
       "activities    -5.969e+09   5.24e+10     -0.114      0.909   -1.09e+11    9.68e+10\n",
       "antianxiety    2.931e+10      3e+10      0.977      0.329   -2.95e+10    8.81e+10\n",
       "antipsychotic  3.539e+10   3.57e+10      0.992      0.321   -3.45e+10    1.05e+11\n",
       "appropriately  -3.28e+10   2.19e+10     -1.496      0.135   -7.58e+10    1.02e+10\n",
       "assessed      -2.656e+10   2.39e+10     -1.112      0.266   -7.34e+10    2.02e+10\n",
       "bladder       -1.863e+11   9.71e+10     -1.919      0.055   -3.77e+11       4e+09\n",
       "bowels          1.28e+11   4.03e+10      3.177      0.001     4.9e+10    2.07e+11\n",
       "catheter       2.363e+11   1.25e+11      1.888      0.059      -9e+09    4.82e+11\n",
       "control        1.105e+11    4.3e+10      2.567      0.010    2.61e+10    1.95e+11\n",
       "daily          1.695e+10    2.4e+10      0.705      0.481   -3.02e+10    6.41e+10\n",
       "depressive    -3.816e+09   5.32e+10     -0.072      0.943   -1.08e+11       1e+11\n",
       "experiencing   1.003e+10   1.29e+11      0.078      0.938   -2.43e+11    2.63e+11\n",
       "falls          1.492e+10   1.33e+11      0.112      0.911   -2.46e+11    2.76e+11\n",
       "function      -6.604e+09    2.6e+10     -0.254      0.799   -5.76e+10    4.43e+10\n",
       "given          1.794e+09   3.75e+10      0.048      0.962   -7.17e+10    7.53e+10\n",
       "help          -8.142e+08   1.36e+10     -0.060      0.952   -2.75e+10    2.59e+10\n",
       "high           1.541e+10      2e+10      0.769      0.442   -2.39e+10    5.47e+10\n",
       "hypnotic       1.279e+09   4.76e+10      0.027      0.979    -9.2e+10    9.45e+10\n",
       "improvements   1.276e+10    2.4e+10      0.531      0.595   -3.43e+10    5.98e+10\n",
       "increased     -1.884e+09   1.38e+10     -0.136      0.892    -2.9e+10    2.52e+10\n",
       "independently  1.602e+10   1.34e+10      1.194      0.232   -1.03e+10    4.23e+10\n",
       "infection      7.501e+09   1.28e+10      0.584      0.559   -1.77e+10    3.27e+10\n",
       "influenza      3.383e+10   3.85e+10      0.880      0.379   -4.16e+10    1.09e+11\n",
       "injury        -9.985e+09    1.3e+11     -0.077      0.939   -2.65e+11    2.45e+11\n",
       "inserted      -4.024e+10   2.74e+10     -1.467      0.142    -9.4e+10    1.35e+10\n",
       "left          -4.056e+10   2.76e+10     -1.472      0.141   -9.46e+10    1.35e+10\n",
       "long          -1.934e+10   3.52e+10     -0.550      0.582   -8.83e+10    4.96e+10\n",
       "lose          -4.741e+09   2.83e+10     -0.168      0.867   -6.02e+10    5.07e+10\n",
       "low           -3.906e+10   3.46e+10     -1.129      0.259   -1.07e+11    2.88e+10\n",
       "major          -8.66e+09   1.23e+11     -0.071      0.944   -2.49e+11    2.32e+11\n",
       "medication    -1.634e+10   2.17e+10     -0.752      0.452   -5.89e+10    2.62e+10\n",
       "need          -1.867e+09   1.38e+10     -0.135      0.892   -2.89e+10    2.52e+10\n",
       "newly            -2.1135      0.118    -17.986      0.000      -2.344      -1.883\n",
       "physically     7.543e+09   1.13e+10      0.670      0.503   -1.45e+10    2.96e+10\n",
       "pneumococcal   5.273e+10   5.83e+10      0.904      0.366   -6.16e+10    1.67e+11\n",
       "pressure       1.182e+10    1.4e+10      0.843      0.399   -1.57e+10    3.93e+10\n",
       "received      -1.634e+10   2.17e+10     -0.752      0.452   -5.89e+10    2.62e+10\n",
       "restrained    -3.595e+09   6.73e+09     -0.534      0.593   -1.68e+10     9.6e+09\n",
       "risk          -3.994e+10   5.11e+10     -0.782      0.434    -1.4e+11    6.02e+10\n",
       "seasonal       1.891e+10      2e+10      0.946      0.344   -2.03e+10    5.81e+10\n",
       "short         -9.652e+09   1.75e+10     -0.550      0.582    -4.4e+10    2.47e+10\n",
       "symptoms       9.838e+09   5.24e+10      0.188      0.851   -9.29e+10    1.13e+11\n",
       "tract         -6.534e+08   3.24e+09     -0.202      0.840      -7e+09    5.69e+09\n",
       "ulcers         1.182e+10    1.4e+10      0.843      0.399   -1.57e+10    3.93e+10\n",
       "urinary       -6.534e+08   3.24e+09     -0.202      0.840      -7e+09    5.69e+09\n",
       "vaccine       -3.714e+08   4.01e+10     -0.009      0.993    -7.9e+10    7.83e+10\n",
       "weight         1.026e+10   1.87e+10      0.549      0.583   -2.64e+10    4.69e+10\n",
       "worsened       1.724e+10   1.31e+10      1.317      0.188   -8.42e+09    4.29e+10\n",
       "==============================================================================\n",
       "Omnibus:                    39930.087   Durbin-Watson:                   1.995\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           604268.632\n",
       "Skew:                          -0.952   Prob(JB):                         0.00\n",
       "Kurtosis:                      12.956   Cond. No.                     3.05e+16\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 1.72e-28. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_TFIDF_train_wconstant = sm.add_constant(X_TFIDF_train)\n",
    "model = sm.OLS(y_train,X_TFIDF_train_wconstant)\n",
    "TFIDF_fitted_lm = model.fit()\n",
    "\n",
    "display(TFIDF_fitted_lm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonahwinninghoff/opt/anaconda3/lib/python3.8/site-packages/statsmodels/tsa/tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n"
     ]
    }
   ],
   "source": [
    "# Create the evaluation using r^2 as a guide\n",
    "def lm_eval(n_components):\n",
    "    pca_train = X_train.iloc[:,0:n_components].copy()\n",
    "    X_train_wconstant = sm.add_constant(pca_train)\n",
    "    model = sm.OLS(y_train,X_train_wconstant)\n",
    "    fitted_lm = model.fit()\n",
    "    return fitted_lm.rsquared\n",
    "\n",
    "components = {}\n",
    "for i in enumerate(X_train.columns):\n",
    "    result = [lm_eval(i[0])]\n",
    "    components[i[1]] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Pandas Frame on components and find max accuracy of n components\n",
    "components = pd.DataFrame(components).melt()\n",
    "max_components = components[components['value'] == np.max(components['value'])].index[0]\n",
    "\n",
    "# Step plot\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.subplots(figsize=(10, 6))\n",
    "plt.plot(components['value'],drawstyle='steps')\n",
    "plt.axvline(max_components, linestyle=':',color='red',linewidth=1)\n",
    "plt.xlabel('Prinicipal components')\n",
    "plt.ylabel('R squared score')\n",
    "plt.title('Prinicipal components and r squared scores', family='monospace',fontsize=16)\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonahwinninghoff/opt/anaconda3/lib/python3.8/site-packages/statsmodels/tsa/tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th>  <td>   0.909</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.909</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>8.342e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 15 Sep 2021</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:23:15</td>     <th>  Log-Likelihood:    </th> <td>1.1011e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>141159</td>      <th>  AIC:               </th> <td>-2.202e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>141141</td>      <th>  BIC:               </th> <td>-2.200e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    17</td>      <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.3573</td> <td>    0.000</td> <td> 1210.121</td> <td> 0.000</td> <td>    0.357</td> <td>    0.358</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pc_0</th>  <td>    0.7746</td> <td>    0.001</td> <td> 1061.483</td> <td> 0.000</td> <td>    0.773</td> <td>    0.776</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pc_1</th>  <td>    0.0366</td> <td>    0.001</td> <td>   38.903</td> <td> 0.000</td> <td>    0.035</td> <td>    0.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pc_2</th>  <td>    0.1458</td> <td>    0.001</td> <td>  129.100</td> <td> 0.000</td> <td>    0.144</td> <td>    0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pc_3</th>  <td>   -0.0082</td> <td>    0.001</td> <td>   -6.848</td> <td> 0.000</td> <td>   -0.011</td> <td>   -0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pc_4</th>  <td>    0.0745</td> <td>    0.001</td> <td>   61.464</td> <td> 0.000</td> <td>    0.072</td> <td>    0.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pc_5</th>  <td>   -0.0313</td> <td>    0.001</td> <td>  -25.601</td> <td> 0.000</td> <td>   -0.034</td> <td>   -0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pc_6</th>  <td>    0.3433</td> <td>    0.001</td> <td>  279.164</td> <td> 0.000</td> <td>    0.341</td> <td>    0.346</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pc_7</th>  <td>   -0.1487</td> <td>    0.001</td> <td> -117.495</td> <td> 0.000</td> <td>   -0.151</td> <td>   -0.146</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pc_8</th>  <td>   -0.0023</td> <td>    0.001</td> <td>   -1.769</td> <td> 0.077</td> <td>   -0.005</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pc_9</th>  <td>   -0.0821</td> <td>    0.001</td> <td>  -60.887</td> <td> 0.000</td> <td>   -0.085</td> <td>   -0.079</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pc_10</th> <td>   -0.0177</td> <td>    0.001</td> <td>  -12.552</td> <td> 0.000</td> <td>   -0.021</td> <td>   -0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pc_11</th> <td>    0.1630</td> <td>    0.001</td> <td>  110.376</td> <td> 0.000</td> <td>    0.160</td> <td>    0.166</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pc_12</th> <td>    0.4478</td> <td>    0.001</td> <td>  299.796</td> <td> 0.000</td> <td>    0.445</td> <td>    0.451</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pc_13</th> <td>   -0.5653</td> <td>    0.002</td> <td> -247.225</td> <td> 0.000</td> <td>   -0.570</td> <td>   -0.561</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pc_14</th> <td>   -0.1624</td> <td>    0.004</td> <td>  -44.051</td> <td> 0.000</td> <td>   -0.170</td> <td>   -0.155</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pc_15</th> <td>   -0.3522</td> <td>    0.004</td> <td>  -87.762</td> <td> 0.000</td> <td>   -0.360</td> <td>   -0.344</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pc_16</th> <td>  -18.7512</td> <td>    1.098</td> <td>  -17.081</td> <td> 0.000</td> <td>  -20.903</td> <td>  -16.600</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pc_17</th> <td> 9.171e-13</td> <td> 5.37e-14</td> <td>   17.088</td> <td> 0.000</td> <td> 8.12e-13</td> <td> 1.02e-12</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>39551.775</td> <th>  Durbin-Watson:     </th>  <td>   1.995</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>602320.938</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-0.937</td>   <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>12.944</td>   <th>  Cond. No.          </th>  <td>1.18e+28</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 1.01e-51. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.909\n",
       "Model:                            OLS   Adj. R-squared:                  0.909\n",
       "Method:                 Least Squares   F-statistic:                 8.342e+04\n",
       "Date:                Wed, 15 Sep 2021   Prob (F-statistic):               0.00\n",
       "Time:                        18:23:15   Log-Likelihood:             1.1011e+05\n",
       "No. Observations:              141159   AIC:                        -2.202e+05\n",
       "Df Residuals:                  141141   BIC:                        -2.200e+05\n",
       "Df Model:                          17                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.3573      0.000   1210.121      0.000       0.357       0.358\n",
       "pc_0           0.7746      0.001   1061.483      0.000       0.773       0.776\n",
       "pc_1           0.0366      0.001     38.903      0.000       0.035       0.038\n",
       "pc_2           0.1458      0.001    129.100      0.000       0.144       0.148\n",
       "pc_3          -0.0082      0.001     -6.848      0.000      -0.011      -0.006\n",
       "pc_4           0.0745      0.001     61.464      0.000       0.072       0.077\n",
       "pc_5          -0.0313      0.001    -25.601      0.000      -0.034      -0.029\n",
       "pc_6           0.3433      0.001    279.164      0.000       0.341       0.346\n",
       "pc_7          -0.1487      0.001   -117.495      0.000      -0.151      -0.146\n",
       "pc_8          -0.0023      0.001     -1.769      0.077      -0.005       0.000\n",
       "pc_9          -0.0821      0.001    -60.887      0.000      -0.085      -0.079\n",
       "pc_10         -0.0177      0.001    -12.552      0.000      -0.021      -0.015\n",
       "pc_11          0.1630      0.001    110.376      0.000       0.160       0.166\n",
       "pc_12          0.4478      0.001    299.796      0.000       0.445       0.451\n",
       "pc_13         -0.5653      0.002   -247.225      0.000      -0.570      -0.561\n",
       "pc_14         -0.1624      0.004    -44.051      0.000      -0.170      -0.155\n",
       "pc_15         -0.3522      0.004    -87.762      0.000      -0.360      -0.344\n",
       "pc_16        -18.7512      1.098    -17.081      0.000     -20.903     -16.600\n",
       "pc_17       9.171e-13   5.37e-14     17.088      0.000    8.12e-13    1.02e-12\n",
       "==============================================================================\n",
       "Omnibus:                    39551.775   Durbin-Watson:                   1.995\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           602320.938\n",
       "Skew:                          -0.937   Prob(JB):                         0.00\n",
       "Kurtosis:                      12.944   Cond. No.                     1.18e+28\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 1.01e-51. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reduce from 49 columns to n_components columns\n",
    "pca_train = X_train.iloc[:,0:max_components]\n",
    "pca_valid = X_valid.iloc[:,0:max_components]\n",
    "pca_test = X_test.iloc[:,0:max_components]\n",
    "\n",
    "# Fit the best lm\n",
    "X_train_wconstant = sm.add_constant(pca_train)\n",
    "model = sm.OLS(y_train,X_train_wconstant)\n",
    "fitted_lm = model.fit()\n",
    "\n",
    "display(fitted_lm.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The OLS with TFIDF vectorization shows that a few variables are statistically significant at two-sided 5% alpha level. The Akaike and Bayesian Information Criterions (AIC and BIC) are −0.98 and −0.977. The R-squared score is 90.9%. The adjusted R-squared score shows that the number of parameters has little impact on the percentage of the target variable variation that this model explains. When the number of features reduces using cosine similarities, each variable is satistically significant at two-sided 1% alpha level, and AIC and BIC are lower. However, the R-squared score is 69.9, and the adjusted R-squared score is same. \n",
    "\n",
    "The kurtosis score lowers but it is still leptokurtotic. The skewness for OLS with TFIDF vectorization is extremely negative. When the cosine similarites are applied, the skewness shifts to postive or right skewness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonahwinninghoff/opt/anaconda3/lib/python3.8/site-packages/statsmodels/tsa/tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n"
     ]
    }
   ],
   "source": [
    "X_valid_wconstant = sm.add_constant(pca_valid)\n",
    "y_predicted = fitted_lm.predict(X_valid_wconstant)\n",
    "\n",
    "X_TFIDF_valid_wconstant = sm.add_constant(X_TFIDF_valid)\n",
    "y_TFIDF_predicted = TFIDF_fitted_lm.predict(X_TFIDF_valid_wconstant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_calculator(predict, true):\n",
    "    merged = pd.concat([pd.DataFrame(list(predict)).rename(columns={0:'predicted'}), \n",
    "           pd.DataFrame(list(true)).rename(columns={0:'true'})],axis=1)\n",
    "    \n",
    "    # 1 - (predict - true)^2/(true - mean(true))^2 = 1 - RSS/TSS = r_2\n",
    "    r2 = 1 - sum((merged['predicted'] - merged['true'])**2)/sum((merged['true'] - np.mean(merged['true']))**2)\n",
    "    \n",
    "    return r2\n",
    "\n",
    "def adjusted_r2_calculator(predict, true):\n",
    "    r2 = r2_calculator(predict, true) # r_2\n",
    "    n = len(true)                     # number of rows\n",
    "    k = len(fitted_lm.params)         # number of parameters\n",
    "    \n",
    "    adj_r2 = 1 - ((1-r2)*(n-1))/(n-k-1)    # 1 - [(1 - r_2)*(n - 1)/(n - k - 1)] = adjusted r^2\n",
    "    \n",
    "    return adj_r2\n",
    "\n",
    "def mae_and_mse_calculator(predict, true):\n",
    "    merged = pd.concat([pd.DataFrame(list(predict)).rename(columns={0:'predicted'}), \n",
    "           pd.DataFrame(list(true)).rename(columns={0:'true'})],axis=1)\n",
    "    mae = sum(np.abs(merged['true'] - merged['predicted']))/len(true) # 1/n ∑ |true - predict|   = MAE\n",
    "    mse = sum((merged['true'] - merged['predicted'])**2)/len(true)    # 1/n ∑ (true - predict)^2 = MSE\n",
    "    \n",
    "    return mae, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set\n",
      "R2: 0.9091\n",
      "Adjusted R2: 0.9091\n",
      "MAE: 0.0686\n",
      "RMSE: 0.1107\n"
     ]
    }
   ],
   "source": [
    "print('Validation Set')\n",
    "print('R2: '+str(round(r2_calculator(y_TFIDF_predicted, y_valid),4)))\n",
    "print('Adjusted R2: '+str(round(adjusted_r2_calculator(y_TFIDF_predicted,y_valid),4)))\n",
    "print('MAE: '+ str(round(mae_and_mse_calculator(y_TFIDF_predicted,y_valid)[0],4)))\n",
    "print('RMSE: '+ str(round(mae_and_mse_calculator(y_TFIDF_predicted,y_valid)[1]**0.5,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set with PCA\n",
      "R2: 0.9091\n",
      "Adjusted R2: 0.9091\n",
      "MAE: 0.0687\n",
      "RMSE: 0.1107\n"
     ]
    }
   ],
   "source": [
    "print('Validation Set with PCA')\n",
    "print('R2: '+str(round(r2_calculator(y_predicted, y_valid),4)))\n",
    "print('Adjusted R2: '+str(round(adjusted_r2_calculator(y_predicted,y_valid),4)))\n",
    "print('MAE: '+ str(round(mae_and_mse_calculator(y_predicted,y_valid)[0],4)))\n",
    "print('RMSE: '+ str(round(mae_and_mse_calculator(y_predicted,y_valid)[1]**0.5,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the model with either TFIDF vectorization or PCA is being generalized using validation set, it is already at highest accuracy and lowest loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression <a id = 'lasso'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |   alpha   |\n",
      "-------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-7.81e-05\u001b[0m | \u001b[0m 0.1131  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-7.81e-05\u001b[0m | \u001b[0m 0.129   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-7.81e-05\u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-7.81e-05\u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m 0.7454  \u001b[0m | \u001b[95m 0.01007 \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.3204  \u001b[0m | \u001b[0m 0.03734 \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-7.81e-05\u001b[0m | \u001b[0m 0.5624  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-7.81e-05\u001b[0m | \u001b[0m 0.3436  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.6187  \u001b[0m | \u001b[0m 0.01727 \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-7.81e-05\u001b[0m | \u001b[0m 0.7812  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-7.81e-05\u001b[0m | \u001b[0m 0.4531  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-7.81e-05\u001b[0m | \u001b[0m 0.6716  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-7.81e-05\u001b[0m | \u001b[0m 0.8904  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-7.81e-05\u001b[0m | \u001b[0m 0.2348  \u001b[0m |\n",
      "| \u001b[95m 15      \u001b[0m | \u001b[95m 0.7464  \u001b[0m | \u001b[95m 0.01    \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.7464  \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.7464  \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.7464  \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.7464  \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.7464  \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.7464  \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.7464  \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "# Optimize Lasso with TFIDF model\n",
    "def lasso_eval(alpha):\n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    lasso.fit(X_TFIDF_train,y_train)\n",
    "    \n",
    "    return r2_calculator(lasso.predict(X_TFIDF_valid),y_valid)\n",
    "    \n",
    "\n",
    "# Instantiate Bayesian Optimization   \n",
    "TFIDF_lassoBO = BayesianOptimization(lasso_eval, {'alpha':(0.01,1)})\n",
    "TFIDF_lassoBO.maximize(n_iter=20, init_points=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |   alpha   |\n",
      "-------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-7.81e-05\u001b[0m | \u001b[0m 0.7301  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-7.81e-05\u001b[0m | \u001b[0m 0.9577  \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.7925  \u001b[0m | \u001b[95m 0.01    \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-7.81e-05\u001b[0m | \u001b[0m 0.2228  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.7925  \u001b[0m | \u001b[0m 0.01001 \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.5473  \u001b[0m | \u001b[0m 0.06197 \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-7.81e-05\u001b[0m | \u001b[0m 0.4846  \u001b[0m |\n",
      "| \u001b[95m 8       \u001b[0m | \u001b[95m 0.7926  \u001b[0m | \u001b[95m 0.01    \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.7926  \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.7926  \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.7926  \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.7926  \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.7926  \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.7926  \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.7926  \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.7926  \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.7926  \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.7926  \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.7926  \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.7926  \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.7926  \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.7926  \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "# Optimize Lasso with TFIDF model\n",
    "def lasso_eval(alpha):\n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    lasso.fit(pca_train,y_train)\n",
    "    \n",
    "    return r2_calculator(lasso.predict(pca_valid),y_valid)\n",
    "    \n",
    "\n",
    "# Instantiate Bayesian Optimization   \n",
    "lassoBO = BayesianOptimization(lasso_eval, {'alpha':(0.01,1)})\n",
    "lassoBO.maximize(n_iter=20, init_points=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.01)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit best models with and without PCA\n",
    "TFIDF_lasso = Lasso(alpha = TFIDF_lassoBO.max['params']['alpha'])\n",
    "TFIDF_lasso.fit(X_TFIDF_train, y_train.ravel())\n",
    "\n",
    "lasso = Lasso(alpha = lassoBO.max['params']['alpha'])\n",
    "lasso.fit(pca_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set\n",
      "R2: 0.7464\n",
      "Adjusted R2: 0.7463\n",
      "MAE: 0.1552\n",
      "RMSE: 0.1849\n"
     ]
    }
   ],
   "source": [
    "print('Validation Set')\n",
    "print('R2: '+str(round(r2_calculator(TFIDF_lasso.predict(X_TFIDF_valid), y_valid),4)))\n",
    "print('Adjusted R2: '+str(round(adjusted_r2_calculator(TFIDF_lasso.predict(X_TFIDF_valid),y_valid),4)))\n",
    "print('MAE: '+ str(round(mae_and_mse_calculator(TFIDF_lasso.predict(X_TFIDF_valid),y_valid)[0],4)))\n",
    "print('RMSE: '+ str(round(mae_and_mse_calculator(TFIDF_lasso.predict(X_TFIDF_valid),y_valid)[1]**0.5,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set with PCA\n",
      "R2: 0.7926\n",
      "Adjusted R2: 0.7925\n",
      "MAE: 0.1329\n",
      "RMSE: 0.1673\n"
     ]
    }
   ],
   "source": [
    "print('Validation Set with PCA')\n",
    "print('R2: '+str(round(r2_calculator(lasso.predict(pca_valid), y_valid),4)))\n",
    "print('Adjusted R2: '+str(round(adjusted_r2_calculator(lasso.predict(pca_valid),y_valid),4)))\n",
    "print('MAE: '+ str(round(mae_and_mse_calculator(lasso.predict(pca_valid),y_valid)[0],4)))\n",
    "print('RMSE: '+ str(round(mae_and_mse_calculator(lasso.predict(pca_valid),y_valid)[1]**0.5,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regression <a id='rfr'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFIDF_rfr_model = RandomForestRegressor()\n",
    "TFIDF_rfr_model.fit(X_TFIDF_train, y_train.ravel())\n",
    "\n",
    "rfr_model = RandomForestRegressor()\n",
    "rfr_model.fit(pca_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set\n",
      "R2: 0.9091\n",
      "Adjusted R2: 0.9091\n",
      "MAE: 0.0687\n",
      "RMSE: 0.1107\n"
     ]
    }
   ],
   "source": [
    "print('Validation Set')\n",
    "print('R2: ' + str(round(r2_calculator(TFIDF_rfr_model.predict(X_TFIDF_valid),y_valid),4)))\n",
    "print('Adjusted R2: ' + str(round(adjusted_r2_calculator(TFIDF_rfr_model.predict(X_TFIDF_valid),y_valid),4)))\n",
    "print('MAE: ' + str(round(mae_and_mse_calculator(TFIDF_rfr_model.predict(X_TFIDF_valid),y_valid)[0],4)))\n",
    "print('RMSE: ' + str(round(mae_and_mse_calculator(TFIDF_rfr_model.predict(X_TFIDF_valid),y_valid)[1]**0.5,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set with PCA\n",
      "R2: 0.9091\n",
      "Adjusted R2: 0.9091\n",
      "MAE: 0.0687\n",
      "RMSE: 0.1107\n"
     ]
    }
   ],
   "source": [
    "print('Validation Set with PCA')\n",
    "print('R2: ' + str(round(r2_calculator(rfr_model.predict(pca_valid),y_valid),4)))\n",
    "print('Adjusted R2: ' + str(round(adjusted_r2_calculator(rfr_model.predict(pca_valid),y_valid),4)))\n",
    "print('MAE: ' + str(round(mae_and_mse_calculator(rfr_model.predict(pca_valid),y_valid)[0],4)))\n",
    "print('RMSE: ' + str(round(mae_and_mse_calculator(rfr_model.predict(pca_valid),y_valid)[1]**0.5,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is identical even with different model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light Gradient Boosting Model With Bayesian Optimization <a id='lgbm'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_eval(lambda_l2,lambda_l1,max_depth,learning_rate,n_estimators):\n",
    "    lgbm_model = LGBMRegressor(lambda_l2 = lambda_l2, lambda_l1 = lambda_l1, \n",
    "                               max_depth = int(round(max_depth,0)),\n",
    "                               learning_rate = learning_rate, \n",
    "                               n_estimators = int(round(n_estimators,0)))\n",
    "    \n",
    "    lgbm_model.fit(pca_train, y_train.ravel())\n",
    "    return r2_calculator(lgbm_model.predict(pca_valid),y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | lambda_l1 | lambda_l2 | learni... | max_depth | n_esti... |\n",
      "-------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.9091  \u001b[0m | \u001b[0m 0.1454  \u001b[0m | \u001b[0m 0.2879  \u001b[0m | \u001b[0m 0.469   \u001b[0m | \u001b[0m 1.65    \u001b[0m | \u001b[0m 108.2   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.9091  \u001b[0m | \u001b[0m 0.106   \u001b[0m | \u001b[0m 0.3295  \u001b[0m | \u001b[0m 0.3927  \u001b[0m | \u001b[0m 4.273   \u001b[0m | \u001b[0m 101.7   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.9091  \u001b[0m | \u001b[0m 0.006879\u001b[0m | \u001b[0m 0.1733  \u001b[0m | \u001b[0m 0.4625  \u001b[0m | \u001b[0m-0.4839  \u001b[0m | \u001b[0m 174.2   \u001b[0m |\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m 0.9091  \u001b[0m | \u001b[95m 0.4807  \u001b[0m | \u001b[95m 0.3549  \u001b[0m | \u001b[95m 0.4336  \u001b[0m | \u001b[95m 1.986   \u001b[0m | \u001b[95m 109.4   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.9091  \u001b[0m | \u001b[0m 0.297   \u001b[0m | \u001b[0m 0.1272  \u001b[0m | \u001b[0m 0.1949  \u001b[0m | \u001b[0m-0.9917  \u001b[0m | \u001b[0m 175.6   \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m 0.9091  \u001b[0m | \u001b[95m 0.3857  \u001b[0m | \u001b[95m 0.3425  \u001b[0m | \u001b[95m 0.4981  \u001b[0m | \u001b[95m 4.704   \u001b[0m | \u001b[95m 161.6   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.9071  \u001b[0m | \u001b[0m 0.4451  \u001b[0m | \u001b[0m 0.009344\u001b[0m | \u001b[0m 0.02166 \u001b[0m | \u001b[0m 4.295   \u001b[0m | \u001b[0m 139.1   \u001b[0m |\n",
      "| \u001b[95m 8       \u001b[0m | \u001b[95m 0.9091  \u001b[0m | \u001b[95m 0.4504  \u001b[0m | \u001b[95m 0.2243  \u001b[0m | \u001b[95m 0.2057  \u001b[0m | \u001b[95m 5.505   \u001b[0m | \u001b[95m 65.62   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.9091  \u001b[0m | \u001b[0m 0.3701  \u001b[0m | \u001b[0m 0.1825  \u001b[0m | \u001b[0m 0.1444  \u001b[0m | \u001b[0m-0.2648  \u001b[0m | \u001b[0m 36.37   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.8497  \u001b[0m | \u001b[0m 0.4633  \u001b[0m | \u001b[0m 0.331   \u001b[0m | \u001b[0m 0.1274  \u001b[0m | \u001b[0m 5.069   \u001b[0m | \u001b[0m 10.08   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.9091  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 6.0     \u001b[0m | \u001b[0m 200.0   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.9091  \u001b[0m | \u001b[0m 0.06517 \u001b[0m | \u001b[0m 0.1809  \u001b[0m | \u001b[0m 0.4596  \u001b[0m | \u001b[0m-0.9252  \u001b[0m | \u001b[0m 51.4    \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.7345  \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m 82.42   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.9091  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m 125.9   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.9091  \u001b[0m | \u001b[0m 0.3392  \u001b[0m | \u001b[0m 0.4675  \u001b[0m | \u001b[0m 0.1672  \u001b[0m | \u001b[0m 5.888   \u001b[0m | \u001b[0m 186.6   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.9091  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m 150.6   \u001b[0m |\n",
      "| \u001b[95m 17      \u001b[0m | \u001b[95m 0.9091  \u001b[0m | \u001b[95m 0.2392  \u001b[0m | \u001b[95m 0.3627  \u001b[0m | \u001b[95m 0.1957  \u001b[0m | \u001b[95m 5.993   \u001b[0m | \u001b[95m 46.39   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.9091  \u001b[0m | \u001b[0m 0.4879  \u001b[0m | \u001b[0m 0.488   \u001b[0m | \u001b[0m 0.3079  \u001b[0m | \u001b[0m-0.991   \u001b[0m | \u001b[0m 193.5   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.6203  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 6.0     \u001b[0m | \u001b[0m 57.34   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.9091  \u001b[0m | \u001b[0m 0.173   \u001b[0m | \u001b[0m 0.4111  \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m 44.36   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.9091  \u001b[0m | \u001b[0m 0.01033 \u001b[0m | \u001b[0m 0.1585  \u001b[0m | \u001b[0m 0.3425  \u001b[0m | \u001b[0m 5.939   \u001b[0m | \u001b[0m 39.09   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.9091  \u001b[0m | \u001b[0m 0.1656  \u001b[0m | \u001b[0m 0.0183  \u001b[0m | \u001b[0m 0.2443  \u001b[0m | \u001b[0m 5.958   \u001b[0m | \u001b[0m 71.92   \u001b[0m |\n",
      "=====================================================================================\n"
     ]
    }
   ],
   "source": [
    "lgbmBO = BayesianOptimization(lgbm_eval, {'lambda_l2':(0, 0.5),\n",
    "                                          'lambda_l1':(0,0.5),\n",
    "                                          'max_depth':(-1,6),\n",
    "                                          'learning_rate':(0.01,0.5),\n",
    "                                          'n_estimators':(10,200)})\n",
    "\n",
    "lgbmBO.maximize(n_iter=20, init_points=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TFIDF_lgbm_eval(lambda_l2,lambda_l1,max_depth,learning_rate,n_estimators):\n",
    "    lgbm_model = LGBMRegressor(lambda_l2 = lambda_l2, lambda_l1 = lambda_l1, \n",
    "                               max_depth = int(round(max_depth,0)),\n",
    "                               learning_rate = learning_rate, \n",
    "                               n_estimators = int(round(n_estimators,0)))\n",
    "    \n",
    "    lgbm_model.fit(X_TFIDF_train, y_train.ravel())\n",
    "    return r2_calculator(lgbm_model.predict(X_TFIDF_valid),y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | lambda_l1 | lambda_l2 | learni... | max_depth | n_esti... |\n",
      "-------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.8702  \u001b[0m | \u001b[0m 0.3884  \u001b[0m | \u001b[0m 0.2732  \u001b[0m | \u001b[0m 0.07349 \u001b[0m | \u001b[0m 0.5105  \u001b[0m | \u001b[0m 93.48   \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.9091  \u001b[0m | \u001b[95m 0.196   \u001b[0m | \u001b[95m 0.2506  \u001b[0m | \u001b[95m 0.3807  \u001b[0m | \u001b[95m 3.377   \u001b[0m | \u001b[95m 45.87   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.7691  \u001b[0m | \u001b[0m 0.2743  \u001b[0m | \u001b[0m 0.1114  \u001b[0m | \u001b[0m 0.02133 \u001b[0m | \u001b[0m 2.794   \u001b[0m | \u001b[0m 46.99   \u001b[0m |\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m 0.9091  \u001b[0m | \u001b[95m 0.1096  \u001b[0m | \u001b[95m 0.1629  \u001b[0m | \u001b[95m 0.293   \u001b[0m | \u001b[95m 3.041   \u001b[0m | \u001b[95m 173.2   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.9091  \u001b[0m | \u001b[0m 0.3473  \u001b[0m | \u001b[0m 0.086   \u001b[0m | \u001b[0m 0.4945  \u001b[0m | \u001b[0m 1.21    \u001b[0m | \u001b[0m 170.3   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.9091  \u001b[0m | \u001b[0m 0.1605  \u001b[0m | \u001b[0m 0.3569  \u001b[0m | \u001b[0m 0.2786  \u001b[0m | \u001b[0m 1.156   \u001b[0m | \u001b[0m 190.9   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.9088  \u001b[0m | \u001b[0m 0.3337  \u001b[0m | \u001b[0m 0.1919  \u001b[0m | \u001b[0m 0.05295 \u001b[0m | \u001b[0m 2.79    \u001b[0m | \u001b[0m 165.5   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.8955  \u001b[0m | \u001b[0m 0.08018 \u001b[0m | \u001b[0m 0.4626  \u001b[0m | \u001b[0m 0.2297  \u001b[0m | \u001b[0m 1.014   \u001b[0m | \u001b[0m 52.08   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.9091  \u001b[0m | \u001b[0m 0.1093  \u001b[0m | \u001b[0m 0.3295  \u001b[0m | \u001b[0m 0.3185  \u001b[0m | \u001b[0m 3.392   \u001b[0m | \u001b[0m 45.66   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.9091  \u001b[0m | \u001b[0m 0.1165  \u001b[0m | \u001b[0m 0.3487  \u001b[0m | \u001b[0m 0.4322  \u001b[0m | \u001b[0m 4.52    \u001b[0m | \u001b[0m 46.03   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.9091  \u001b[0m | \u001b[0m 0.3703  \u001b[0m | \u001b[0m 0.2297  \u001b[0m | \u001b[0m 0.3142  \u001b[0m | \u001b[0m 4.317   \u001b[0m | \u001b[0m 44.61   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.9091  \u001b[0m | \u001b[0m 0.4553  \u001b[0m | \u001b[0m 0.2403  \u001b[0m | \u001b[0m 0.1387  \u001b[0m | \u001b[0m 5.341   \u001b[0m | \u001b[0m 45.02   \u001b[0m |\n",
      "| \u001b[95m 13      \u001b[0m | \u001b[95m 0.9091  \u001b[0m | \u001b[95m 0.0     \u001b[0m | \u001b[95m 0.0     \u001b[0m | \u001b[95m 0.5     \u001b[0m | \u001b[95m 5.327   \u001b[0m | \u001b[95m 43.86   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.9091  \u001b[0m | \u001b[0m 0.3745  \u001b[0m | \u001b[0m 0.05293 \u001b[0m | \u001b[0m 0.3108  \u001b[0m | \u001b[0m 1.921   \u001b[0m | \u001b[0m 171.6   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.9091  \u001b[0m | \u001b[0m 0.1056  \u001b[0m | \u001b[0m 0.2285  \u001b[0m | \u001b[0m 0.313   \u001b[0m | \u001b[0m 1.563   \u001b[0m | \u001b[0m 172.9   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.9091  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.3122  \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.6703  \u001b[0m | \u001b[0m 171.6   \u001b[0m |\n",
      "| \u001b[95m 17      \u001b[0m | \u001b[95m 0.9091  \u001b[0m | \u001b[95m 0.2853  \u001b[0m | \u001b[95m 0.3332  \u001b[0m | \u001b[95m 0.4683  \u001b[0m | \u001b[95m 3.219   \u001b[0m | \u001b[95m 172.0   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.9091  \u001b[0m | \u001b[0m 0.1329  \u001b[0m | \u001b[0m 0.09076 \u001b[0m | \u001b[0m 0.4135  \u001b[0m | \u001b[0m 2.809   \u001b[0m | \u001b[0m 170.2   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.9091  \u001b[0m | \u001b[0m 0.3342  \u001b[0m | \u001b[0m 0.4836  \u001b[0m | \u001b[0m 0.2074  \u001b[0m | \u001b[0m 1.97    \u001b[0m | \u001b[0m 168.9   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.9086  \u001b[0m | \u001b[0m 0.02692 \u001b[0m | \u001b[0m 0.1827  \u001b[0m | \u001b[0m 0.1971  \u001b[0m | \u001b[0m 0.5076  \u001b[0m | \u001b[0m 168.8   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.9088  \u001b[0m | \u001b[0m 0.139   \u001b[0m | \u001b[0m 0.02558 \u001b[0m | \u001b[0m 0.211   \u001b[0m | \u001b[0m 1.419   \u001b[0m | \u001b[0m 167.6   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.9091  \u001b[0m | \u001b[0m 0.2434  \u001b[0m | \u001b[0m 0.212   \u001b[0m | \u001b[0m 0.4864  \u001b[0m | \u001b[0m 2.696   \u001b[0m | \u001b[0m 166.9   \u001b[0m |\n",
      "=====================================================================================\n"
     ]
    }
   ],
   "source": [
    "TFIDF_lgbmBO = BayesianOptimization(TFIDF_lgbm_eval, {'lambda_l2':(0, 0.5),\n",
    "                                          'lambda_l1':(0,0.5),\n",
    "                                          'max_depth':(-1,6),\n",
    "                                          'learning_rate':(0.01,0.5),\n",
    "                                          'n_estimators':(10,200)})\n",
    "\n",
    "TFIDF_lgbmBO.maximize(n_iter=20, init_points=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lambda_l1': 0.23919026602832588, 'lambda_l2': 0.3627241902938171, 'learning_rate': 0.19571053687205453, 'max_depth': 5.993480211264609, 'n_estimators': 46.39378407684369}\n",
      "{'lambda_l1': 0.28525283908447346, 'lambda_l2': 0.33317168991051427, 'learning_rate': 0.46829356000044503, 'max_depth': 3.218928149681375, 'n_estimators': 172.0227938688183}\n"
     ]
    }
   ],
   "source": [
    "print(lgbmBO.max['params'])\n",
    "print(TFIDF_lgbmBO.max['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(lambda_l1=0.3627241902938171, lambda_l2=0.23919026602832588,\n",
       "              learning_rate=0.19571053687205453, max_depth=6, n_estimators=46)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_model = LGBMRegressor(lambda_l2 = lgbmBO.max['params']['lambda_l1'],\n",
    "                           lambda_l1 = lgbmBO.max['params']['lambda_l2'],\n",
    "                           max_depth = int(round(lgbmBO.max['params']['max_depth'],0)),\n",
    "                           learning_rate = lgbmBO.max['params']['learning_rate'],\n",
    "                           n_estimators = int(round(lgbmBO.max['params']['n_estimators'],0)))\n",
    "lgbm_model.fit(pca_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(lambda_l1=0.33317168991051427, lambda_l2=0.28525283908447346,\n",
       "              learning_rate=0.46829356000044503, max_depth=3, n_estimators=172)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFIDF_lgbm_model = LGBMRegressor(lambda_l2 = TFIDF_lgbmBO.max['params']['lambda_l1'],\n",
    "                           lambda_l1 = TFIDF_lgbmBO.max['params']['lambda_l2'],\n",
    "                           max_depth = int(round(TFIDF_lgbmBO.max['params']['max_depth'],0)),\n",
    "                           learning_rate = TFIDF_lgbmBO.max['params']['learning_rate'],\n",
    "                           n_estimators = int(round(TFIDF_lgbmBO.max['params']['n_estimators'],0)))\n",
    "TFIDF_lgbm_model.fit(X_TFIDF_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set\n",
      "R2: 0.9091\n",
      "Adjusted R2: 0.9091\n",
      "MAE: 0.0687\n",
      "RMSE: 0.1107\n"
     ]
    }
   ],
   "source": [
    "print('Validation Set')\n",
    "print('R2: ' + str(round(r2_calculator(TFIDF_lgbm_model.predict(X_TFIDF_valid),y_valid),4)))\n",
    "print('Adjusted R2: ' + str(round(adjusted_r2_calculator(TFIDF_lgbm_model.predict(X_TFIDF_valid),y_valid),4)))\n",
    "print('MAE: ' + str(round(mae_and_mse_calculator(TFIDF_lgbm_model.predict(X_TFIDF_valid),y_valid)[0],4)))\n",
    "print('RMSE: ' + str(round(mae_and_mse_calculator(TFIDF_lgbm_model.predict(X_TFIDF_valid),y_valid)[1]**0.5,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set with PCA\n",
      "R2: 0.9091\n",
      "Adjusted R2: 0.9091\n",
      "MAE: 0.0687\n",
      "RMSE: 0.1107\n"
     ]
    }
   ],
   "source": [
    "print('Validation Set with PCA')\n",
    "print('R2: ' + str(round(r2_calculator(lgbm_model.predict(pca_valid),y_valid),4)))\n",
    "print('Adjusted R2: ' + str(round(adjusted_r2_calculator(lgbm_model.predict(pca_valid),y_valid),4)))\n",
    "print('MAE: ' + str(round(mae_and_mse_calculator(lgbm_model.predict(pca_valid),y_valid)[0],4)))\n",
    "print('RMSE: ' + str(round(mae_and_mse_calculator(lgbm_model.predict(pca_valid),y_valid)[1]**0.5,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the hyperparameter search completes, the result indicates that the error is irreducible. Two ways to reduce this error are feature engineering and data wrangling. Besides this, the random forest model is top choice for this problem because this model is more resistant to overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Set with PCA\n",
      "R2: 0.9097\n",
      "Adjusted R2: 0.9097\n",
      "MAE: 0.0685\n",
      "RMSE: 0.1106\n"
     ]
    }
   ],
   "source": [
    "print('Testing Set with PCA')\n",
    "print('R2: ' + str(round(r2_calculator(rfr_model.predict(pca_test),y_test),4)))\n",
    "print('Adjusted R2: ' + str(round(adjusted_r2_calculator(rfr_model.predict(pca_test),y_test),4)))\n",
    "print('MAE: ' + str(round(mae_and_mse_calculator(rfr_model.predict(pca_test),y_test)[0],4)))\n",
    "print('RMSE: ' + str(round(mae_and_mse_calculator(rfr_model.predict(pca_test),y_test)[1]**0.5,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run: 140.35292172431946 seconds\n"
     ]
    }
   ],
   "source": [
    "print(f'Time taken to run: {time.time() - start} seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
