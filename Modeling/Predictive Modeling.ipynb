{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection and Modeling\n",
    "\n",
    "- [Linear Regression: OLS](#lm)\n",
    "- [Random Forest Regression](#rfr)\n",
    "- [Light Gradient Boosting Model With Bayesian Optimization](#lgbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Necessary Modules and Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tools to get datasets\n",
    "import urllib\n",
    "import requests\n",
    "import io\n",
    "\n",
    "# Import modules for data reading and plots\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Import all for model selections and modelling\n",
    "from bayes_opt import BayesianOptimization\n",
    "import statsmodels.api as sm\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time() # Timer starts\n",
    "\n",
    "Xtrainurl = 'https://raw.githubusercontent.com/jonahwinninghoff/Springboard_Capstone_Project/main/Assets/X_train'\n",
    "Xvalidurl = 'https://raw.githubusercontent.com/jonahwinninghoff/Springboard_Capstone_Project/main/Assets/X_valid'\n",
    "Xtestiurl = 'https://raw.githubusercontent.com/jonahwinninghoff/Springboard_Capstone_Project/main/Assets/X_test'\n",
    "\n",
    "ytrainurl = 'https://github.com/jonahwinninghoff/Springboard_Capstone_Project/blob/main/Assets/y_train?raw=true'\n",
    "yvalidurl = 'https://github.com/jonahwinninghoff/Springboard_Capstone_Project/blob/main/Assets/y_valid?raw=true'\n",
    "ytestiurl = 'https://github.com/jonahwinninghoff/Springboard_Capstone_Project/blob/main/Assets/y_test?raw=true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read X_train dataset\n",
    "url = urllib.request.urlopen(Xtrainurl)\n",
    "file = io.BytesIO(url.read())\n",
    "X_train = pd.read_csv(file, encoding='cp1252').drop('Unnamed: 0', \n",
    "                                                    axis=1)\n",
    "\n",
    "# Read X_valid dataset\n",
    "url = urllib.request.urlopen(Xvalidurl)\n",
    "file = io.BytesIO(url.read())\n",
    "X_valid = pd.read_csv(file, encoding='cp1252').drop('Unnamed: 0', \n",
    "                                                    axis=1)\n",
    "\n",
    "# Read X_test dataset\n",
    "url = urllib.request.urlopen(Xtestiurl)\n",
    "file = io.BytesIO(url.read())\n",
    "X_test = pd.read_csv(file, encoding='cp1252').drop('Unnamed: 0', \n",
    "                                                    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read y_train dataset\n",
    "response = requests.get(ytrainurl)\n",
    "response.raise_for_status()\n",
    "y_train = np.load(io.BytesIO(response.content))\n",
    "\n",
    "# Read y_valid dataset\n",
    "response = requests.get(yvalidurl)\n",
    "response.raise_for_status()\n",
    "y_valid = np.load(io.BytesIO(response.content))\n",
    "\n",
    "# Read y_test dataset\n",
    "response = requests.get(ytestiurl)\n",
    "response.raise_for_status()\n",
    "y_test = np.load(io.BytesIO(response.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression: OLS <a id ='lm'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th>  <td>   0.696</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.696</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>6.464e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 03 Sep 2021</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:08:05</td>     <th>  Log-Likelihood:    </th>  <td>  24551.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>141159</td>      <th>  AIC:               </th> <td>-4.909e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>141153</td>      <th>  BIC:               </th> <td>-4.903e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>          <td>    0.1596</td> <td>    0.007</td> <td>   23.924</td> <td> 0.000</td> <td>    0.146</td> <td>    0.173</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cosine median</th>  <td>   -0.0452</td> <td>    0.002</td> <td>  -19.139</td> <td> 0.000</td> <td>   -0.050</td> <td>   -0.041</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cosine mean</th>    <td>    0.7183</td> <td>    0.015</td> <td>   47.088</td> <td> 0.000</td> <td>    0.688</td> <td>    0.748</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cosine minimum</th> <td>   -0.1735</td> <td>    0.009</td> <td>  -20.246</td> <td> 0.000</td> <td>   -0.190</td> <td>   -0.157</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cosine maximum</th> <td>    0.6937</td> <td>    0.003</td> <td>  198.503</td> <td> 0.000</td> <td>    0.687</td> <td>    0.701</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cosine std</th>     <td>   -0.6243</td> <td>    0.035</td> <td>  -18.031</td> <td> 0.000</td> <td>   -0.692</td> <td>   -0.556</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>16213.742</td> <th>  Durbin-Watson:     </th> <td>   1.995</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>28286.985</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 0.786</td>   <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 4.530</td>   <th>  Cond. No.          </th> <td>    80.1</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.696\n",
       "Model:                            OLS   Adj. R-squared:                  0.696\n",
       "Method:                 Least Squares   F-statistic:                 6.464e+04\n",
       "Date:                Fri, 03 Sep 2021   Prob (F-statistic):               0.00\n",
       "Time:                        11:08:05   Log-Likelihood:                 24551.\n",
       "No. Observations:              141159   AIC:                        -4.909e+04\n",
       "Df Residuals:                  141153   BIC:                        -4.903e+04\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==================================================================================\n",
       "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------\n",
       "const              0.1596      0.007     23.924      0.000       0.146       0.173\n",
       "cosine median     -0.0452      0.002    -19.139      0.000      -0.050      -0.041\n",
       "cosine mean        0.7183      0.015     47.088      0.000       0.688       0.748\n",
       "cosine minimum    -0.1735      0.009    -20.246      0.000      -0.190      -0.157\n",
       "cosine maximum     0.6937      0.003    198.503      0.000       0.687       0.701\n",
       "cosine std        -0.6243      0.035    -18.031      0.000      -0.692      -0.556\n",
       "==============================================================================\n",
       "Omnibus:                    16213.742   Durbin-Watson:                   1.995\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            28286.985\n",
       "Skew:                           0.786   Prob(JB):                         0.00\n",
       "Kurtosis:                       4.530   Cond. No.                         80.1\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train = sm.add_constant(X_train)\n",
    "model = sm.OLS(y_train,X_train)\n",
    "fitted_lm = model.fit()\n",
    "\n",
    "display(fitted_lm.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each variable is statistically significant at two-sided 1% alpha level. The F-statistics shows that at least one variable has a significant impact on target variable. The R-squared score is 69.6%. The adjusted R-squared score shows that increase in number of parameters has no effect on R-squared score. Akaike and Bayesian Information Criterion are -9.344 and −9.327, respectively. This needs to evaluate by comparing TFIDF without cosine similarities. In general sense, the lower the score is, the better this model is. The skewness is 0.789, which is not a problem. The kurtosis score shows that this distribution is leptokurtotic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = sm.add_constant(X_valid)\n",
    "y_predicted = fitted_lm.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_calculator(predict, true):\n",
    "    merged = pd.concat([pd.DataFrame(list(predict)).rename(columns={0:'predicted'}), \n",
    "           pd.DataFrame(list(true)).rename(columns={0:'true'})],axis=1)\n",
    "    \n",
    "    # 1 - (predict - true)^2/(true - mean(true))^2 = 1 - RSS/TSS = r_2\n",
    "    r2 = 1 - sum((merged['predicted'] - merged['true'])**2)/sum((merged['true'] - np.mean(merged['true']))**2)\n",
    "    \n",
    "    return r2\n",
    "\n",
    "def adjusted_r2_calculator(predict, true):\n",
    "    r2 = r2_calculator(predict, true) # r_2\n",
    "    n = len(true)                     # number of rows\n",
    "    k = len(fitted_lm.params)         # number of parameters\n",
    "    \n",
    "    adj_r2 = 1 - ((1-r2)*(n-1))/(n-k-1)    # 1 - [(1 - r_2)*(n - 1)/(n - k - 1)] = adjusted r^2\n",
    "    \n",
    "    return adj_r2\n",
    "\n",
    "def mae_and_mse_calculator(predict, true):\n",
    "    merged = pd.concat([pd.DataFrame(list(predict)).rename(columns={0:'predicted'}), \n",
    "           pd.DataFrame(list(true)).rename(columns={0:'true'})],axis=1)\n",
    "    mae = sum(np.abs(merged['true'] - merged['predicted']))/len(true) # 1/n ∑ |true - predict|   = MAE\n",
    "    mse = sum((merged['true'] - merged['predicted'])**2)/len(true)    # 1/n ∑ (true - predict)^2 = MSE\n",
    "    \n",
    "    return mae, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set\n",
      "R2: 0.6928\n",
      "Adjusted R2: 0.6928\n",
      "MAE: 0.1531\n",
      "RMSE: 0.2036\n"
     ]
    }
   ],
   "source": [
    "print('Validation Set')\n",
    "print('R2: '+str(round(r2_calculator(y_predicted, y_valid),4)))\n",
    "print('Adjusted R2: '+str(round(adjusted_r2_calculator(y_predicted,y_valid),4)))\n",
    "print('MAE: '+ str(round(mae_and_mse_calculator(y_predicted,y_valid)[0],4)))\n",
    "print('RMSE: '+ str(round(mae_and_mse_calculator(y_predicted,y_valid)[1]**0.5,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the model is being generalized using the validation set, the R2 score decreases from 69.6% to 69.28%. The RMSE score shows that if the target variable is 50%, then it can be either 70.36% and 29.64%. The MAE score means that if it is 50%, it can be either 65.13% and 34.87%. Non-differentiable although the MAE is, it is resistant to outliers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regression <a id='rfr'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr_model = RandomForestRegressor()\n",
    "rfr_model.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set\n",
      "R2: 0.9091\n",
      "Adjusted R2: 0.9091\n",
      "MAE: 0.0687\n",
      "RMSE: 0.1107\n"
     ]
    }
   ],
   "source": [
    "print('Validation Set')\n",
    "print('R2: ' + str(round(r2_calculator(rfr_model.predict(X_valid),y_valid),4)))\n",
    "print('Adjusted R2: ' + str(round(adjusted_r2_calculator(rfr_model.predict(X_valid),y_valid),4)))\n",
    "print('MAE: ' + str(round(mae_and_mse_calculator(rfr_model.predict(X_valid),y_valid)[0],4)))\n",
    "print('RMSE: ' + str(round(mae_and_mse_calculator(rfr_model.predict(X_valid),y_valid)[1]**0.5,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, the R2 and Adjusted R2 are increased. The MAE and RMSE are decreased. In other words, the random forest model outperforms the OLS model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Light Gradient Boosting Model With Bayesian Optimization <a id='lgbm'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_eval(lambda_l2,lambda_l1,max_depth,learning_rate,n_estimators):\n",
    "    lgbm_model = LGBMRegressor(lambda_l2 = lambda_l2, lambda_l1 = lambda_l1, \n",
    "                               max_depth = int(round(max_depth,0)),\n",
    "                               learning_rate = learning_rate, \n",
    "                               n_estimators = int(round(n_estimators,0)))\n",
    "    \n",
    "    lgbm_model.fit(X_train, y_train.ravel())\n",
    "    return r2_calculator(lgbm_model.predict(X_valid),y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | lambda_l1 | lambda_l2 | learni... | max_depth | n_esti... |\n",
      "-------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.9091  \u001b[0m | \u001b[0m 0.1413  \u001b[0m | \u001b[0m 0.1312  \u001b[0m | \u001b[0m 0.3061  \u001b[0m | \u001b[0m 3.908   \u001b[0m | \u001b[0m 175.7   \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.9091  \u001b[0m | \u001b[95m 0.3944  \u001b[0m | \u001b[95m 0.2276  \u001b[0m | \u001b[95m 0.3327  \u001b[0m | \u001b[95m 4.729   \u001b[0m | \u001b[95m 137.5   \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.9091  \u001b[0m | \u001b[95m 0.4067  \u001b[0m | \u001b[95m 0.4972  \u001b[0m | \u001b[95m 0.07254 \u001b[0m | \u001b[95m 5.872   \u001b[0m | \u001b[95m 137.1   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.9091  \u001b[0m | \u001b[0m 0.1751  \u001b[0m | \u001b[0m 0.3837  \u001b[0m | \u001b[0m 0.4774  \u001b[0m | \u001b[0m 5.778   \u001b[0m | \u001b[0m 136.2   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.9091  \u001b[0m | \u001b[0m 0.4002  \u001b[0m | \u001b[0m 0.3125  \u001b[0m | \u001b[0m 0.183   \u001b[0m | \u001b[0m 4.855   \u001b[0m | \u001b[0m 137.5   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.9091  \u001b[0m | \u001b[0m 0.4001  \u001b[0m | \u001b[0m 0.2491  \u001b[0m | \u001b[0m 0.2314  \u001b[0m | \u001b[0m 5.922   \u001b[0m | \u001b[0m 137.4   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.9091  \u001b[0m | \u001b[0m 0.2171  \u001b[0m | \u001b[0m 0.4457  \u001b[0m | \u001b[0m 0.3516  \u001b[0m | \u001b[0m 5.861   \u001b[0m | \u001b[0m 137.1   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.9091  \u001b[0m | \u001b[0m 0.2702  \u001b[0m | \u001b[0m 0.4877  \u001b[0m | \u001b[0m 0.1242  \u001b[0m | \u001b[0m 5.826   \u001b[0m | \u001b[0m 136.8   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.9091  \u001b[0m | \u001b[0m 0.2792  \u001b[0m | \u001b[0m 0.2543  \u001b[0m | \u001b[0m 0.4018  \u001b[0m | \u001b[0m 4.794   \u001b[0m | \u001b[0m 137.4   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.9083  \u001b[0m | \u001b[0m 0.2033  \u001b[0m | \u001b[0m 0.3061  \u001b[0m | \u001b[0m 0.3424  \u001b[0m | \u001b[0m 1.417   \u001b[0m | \u001b[0m 141.8   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.9091  \u001b[0m | \u001b[0m 0.3124  \u001b[0m | \u001b[0m 0.2264  \u001b[0m | \u001b[0m 0.46    \u001b[0m | \u001b[0m 4.785   \u001b[0m | \u001b[0m 185.3   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.9091  \u001b[0m | \u001b[0m 0.357   \u001b[0m | \u001b[0m 0.3582  \u001b[0m | \u001b[0m 0.1765  \u001b[0m | \u001b[0m-0.9231  \u001b[0m | \u001b[0m 193.3   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.9091  \u001b[0m | \u001b[0m 0.3718  \u001b[0m | \u001b[0m 0.4719  \u001b[0m | \u001b[0m 0.4498  \u001b[0m | \u001b[0m 5.966   \u001b[0m | \u001b[0m 199.3   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.9091  \u001b[0m | \u001b[0m 0.3037  \u001b[0m | \u001b[0m 0.1403  \u001b[0m | \u001b[0m 0.212   \u001b[0m | \u001b[0m-0.8366  \u001b[0m | \u001b[0m 167.6   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.9091  \u001b[0m | \u001b[0m 0.1683  \u001b[0m | \u001b[0m 0.4271  \u001b[0m | \u001b[0m 0.07347 \u001b[0m | \u001b[0m 5.809   \u001b[0m | \u001b[0m 162.2   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.9091  \u001b[0m | \u001b[0m 0.3183  \u001b[0m | \u001b[0m 0.2199  \u001b[0m | \u001b[0m 0.4933  \u001b[0m | \u001b[0m-0.976   \u001b[0m | \u001b[0m 181.4   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.8714  \u001b[0m | \u001b[0m 0.4035  \u001b[0m | \u001b[0m 0.4229  \u001b[0m | \u001b[0m 0.4874  \u001b[0m | \u001b[0m 0.8583  \u001b[0m | \u001b[0m 10.2    \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.7634  \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m 90.69   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.9091  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m 200.0   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.9091  \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m 156.2   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.9091  \u001b[0m | \u001b[0m 0.466   \u001b[0m | \u001b[0m 0.1588  \u001b[0m | \u001b[0m 0.2707  \u001b[0m | \u001b[0m 5.944   \u001b[0m | \u001b[0m 151.9   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.9081  \u001b[0m | \u001b[0m 0.07767 \u001b[0m | \u001b[0m 0.1246  \u001b[0m | \u001b[0m 0.01735 \u001b[0m | \u001b[0m 5.939   \u001b[0m | \u001b[0m 192.8   \u001b[0m |\n",
      "=====================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lgbmBO = BayesianOptimization(lgbm_eval, {'lambda_l2':(0, 0.5),\n",
    "                                          'lambda_l1':(0,0.5),\n",
    "                                          'max_depth':(-1,6),\n",
    "                                          'learning_rate':(0.01,0.5),\n",
    "                                          'n_estimators':(10,200)})\n",
    "\n",
    "lgbmBO.maximize(n_iter=20, init_points=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lambda_l1': 0.4066706373447378, 'lambda_l2': 0.4972157734835887, 'learning_rate': 0.0725439481936864, 'max_depth': 5.8722982849661, 'n_estimators': 137.05887878322778}\n"
     ]
    }
   ],
   "source": [
    "print(lgbmBO.max['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(lambda_l1=0.4972157734835887, lambda_l2=0.4066706373447378,\n",
       "              learning_rate=0.0725439481936864, max_depth=6, n_estimators=137)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_model = LGBMRegressor(lambda_l2 = lgbmBO.max['params']['lambda_l1'],\n",
    "                           lambda_l1 = lgbmBO.max['params']['lambda_l2'],\n",
    "                           max_depth = int(round(lgbmBO.max['params']['max_depth'],0)),\n",
    "                           learning_rate = lgbmBO.max['params']['learning_rate'],\n",
    "                           n_estimators = int(round(lgbmBO.max['params']['n_estimators'],0)))\n",
    "lgbm_model.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set\n",
      "R2: 0.9091\n",
      "Adjusted R2: 0.9091\n",
      "MAE: 0.0687\n",
      "RMSE: 0.1107\n"
     ]
    }
   ],
   "source": [
    "print('Validation Set')\n",
    "print('R2: ' + str(round(r2_calculator(lgbm_model.predict(X_valid),y_valid),4)))\n",
    "print('Adjusted R2: ' + str(round(adjusted_r2_calculator(lgbm_model.predict(X_valid),y_valid),4)))\n",
    "print('MAE: ' + str(round(mae_and_mse_calculator(lgbm_model.predict(X_valid),y_valid)[0],4)))\n",
    "print('RMSE: ' + str(round(mae_and_mse_calculator(lgbm_model.predict(X_valid),y_valid)[1]**0.5,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the hyperparameter search completes, the result indicates that the error is irreducible. Two ways to reduce this error are feature engineering and data wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run: 32.09386587142944 seconds\n"
     ]
    }
   ],
   "source": [
    "print(f'Time taken to run: {time.time() - start} seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
