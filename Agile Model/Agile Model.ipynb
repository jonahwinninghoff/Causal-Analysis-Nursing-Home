{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content\n",
    "- **[Import Necessary Packages](#packages)**\n",
    "- **[Baseline Feature Engineering](#bfeatures)**\n",
    "- **[Baseline Modeling](#bmodeling)**\n",
    "- **[Feature Engineering No.1](#features1)**\n",
    "- **[Modeling No.1](#modeling1)**\n",
    "- **[Feature Engineering No.2](#features2)**\n",
    "- **[Modeling No.2](#modeling2)**\n",
    "- **[Modeling No.3](#modeling3)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Necessary Packages <a id = 'packages'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "import urllib\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import sklearn.model_selection as m_sel\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtain the cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Unzip and read file\n",
    "url = urllib.request.urlopen('https://github.com/jonahwinninghoff/Springboard_Capstone_Project/raw/main/Assets/neat_data.zip')\n",
    "file = ZipFile(BytesIO(url.read()))\n",
    "cleaned_json = file.open(\"neat_data\")\n",
    "clean_df = pd.read_json(cleaned_json, encoding='cp1252')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Provider Name                                object\n",
       "Provider Address                             object\n",
       "Provider City                                object\n",
       "Provider State                               object\n",
       "Provider Zip Code                             int64\n",
       "Measure Code                                  int64\n",
       "Measure Description                          object\n",
       "Resident type                                object\n",
       "Q1 Measure Score                            float64\n",
       "Q2 Measure Score                            float64\n",
       "Q3 Measure Score                            float64\n",
       "Q4 Measure Score                            float64\n",
       "Four Quarter Average Score                  float64\n",
       "Used in Quality Measure Five Star Rating     object\n",
       "Location                                     object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(clean_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Feature Engineering <a id = 'bfeatures'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Vectorize Measure Description\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words = 'english', max_df = 0.25, min_df = 5)\n",
    "vectorized_array = vectorizer.fit_transform(clean_df['Measure Description']).toarray()\n",
    "names_list = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add new right columns\n",
    "df = pd.DataFrame(vectorized_array.tolist()) # Coerce array into dataframe\n",
    "\n",
    "columns_renamed = {}                         # Create renamed column dictionary\n",
    "for i in enumerate(names_list):\n",
    "    columns_renamed[i[0]] = i[1]\n",
    "cleanup = df.rename(columns = columns_renamed) # 0, 1, ..., 51 -> ability, activities, ..., worsened\n",
    "\n",
    "cleaned_df = clean_df.merge(cleanup,         # Inner Join Tfidf with cleaned_df on index\n",
    "                              left_index=True, \n",
    "                              right_index=True, \n",
    "                              how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df['Binary Score'] = np.where(cleaned_df['Four Quarter Average Score'] <= 50, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select key columns for this model\n",
    "names_list.extend(['Binary Score'])\n",
    "dataset = cleaned_df[names_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Modeling <a id = 'bmodeling'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split testing, validating, and training\n",
    "dataset_X, dataset_y = dataset.iloc[:,:-1], dataset.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = m_sel.train_test_split(dataset_X, dataset_y, \n",
    "                                                    test_size=0.33, \n",
    "                                                    random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n"
     ]
    }
   ],
   "source": [
    "# Create 10 folds of cross validation and use logit regression\n",
    "model = LogisticRegression()\n",
    "cv = m_sel.KFold(n_splits=10, random_state=444, shuffle=True)\n",
    "print(model.fit(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the 10 fold average metrics\n",
    "thenames = ['Accuracy','Precision','Mean Absolute Error','Brier Score']\n",
    "scorings = ['accuracy', 'average_precision','neg_mean_absolute_error','neg_mean_squared_error']\n",
    "scores = {}\n",
    "\n",
    "for i in enumerate(thenames):\n",
    "    scores[thenames[i[0]]] = m_sel.cross_val_score(model, \n",
    "                                                   X_train, y_train,\n",
    "                                                   cv=cv, scoring=scorings[i[0]])\n",
    "    scores[thenames[i[0]]] = np.absolute(round(np.mean(scores[thenames[i[0]]]),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Accuracy': 0.679, 'Precision': 0.319, 'Mean Absolute Error': 0.321, 'Brier Score': 0.321}\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering No.1 <a id ='features1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove max_df and min_df\n",
    "vectorizer = TfidfVectorizer(stop_words = 'english')\n",
    "vectorized_array = vectorizer.fit_transform(clean_df['Measure Description']).toarray()\n",
    "names_list = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add new right columns\n",
    "df = pd.DataFrame(vectorized_array.tolist()) # Coerce array into dataframe\n",
    "\n",
    "columns_renamed = {}                         # Create renamed column dictionary\n",
    "for i in enumerate(names_list):\n",
    "    columns_renamed[i[0]] = i[1]\n",
    "cleanup = df.rename(columns = columns_renamed) # 0, 1, ..., 51 -> ability, activities, ..., worsened\n",
    "\n",
    "cleaned_df1 = clean_df.merge(cleanup,         # Inner Join Tfidf with cleaned_df on index\n",
    "                              left_index=True, \n",
    "                              right_index=True, \n",
    "                              how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df1['Binary Score'] = np.where(cleaned_df1['Four Quarter Average Score'] <= 50, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select key columns for this model\n",
    "names_list.extend(['Binary Score'])\n",
    "dataset1 = cleaned_df1[names_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset1.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling No.1 <a id = 'modeling1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split testing, validating, and training\n",
    "dataset1_X, dataset1_y = dataset1.iloc[:,:-1], dataset1.iloc[:,-1]\n",
    "X_train1, X_test1, y_train1, y_test1 = m_sel.train_test_split(dataset1_X, dataset1_y, \n",
    "                                                    test_size=0.33, \n",
    "                                                    random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n"
     ]
    }
   ],
   "source": [
    "# Create 10 folds of cross validation and use logit regression\n",
    "model1 = LogisticRegression()\n",
    "cv = m_sel.KFold(n_splits=10, random_state=444, shuffle=True)\n",
    "print(model1.fit(X_train1, y_train1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the 10 fold average metrics\n",
    "thenames1 = ['Accuracy','Precision','Mean Absolute Error','Brier Score']\n",
    "scorings1 = ['accuracy', 'average_precision','neg_mean_absolute_error','neg_mean_squared_error']\n",
    "scores1 = {}\n",
    "\n",
    "for i in enumerate(thenames):\n",
    "    scores1[thenames1[i[0]]] = m_sel.cross_val_score(model1, \n",
    "                                                   X_train1, y_train1,\n",
    "                                                   cv=cv, scoring=scorings1[i[0]])\n",
    "    scores1[thenames1[i[0]]] = np.absolute(round(np.mean(scores1[thenames1[i[0]]]),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Accuracy': 0.679, 'Precision': 0.319, 'Mean Absolute Error': 0.321, 'Brier Score': 0.321}\n"
     ]
    }
   ],
   "source": [
    "print(scores1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering No.2 <a id='features2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Vectorize Measure Description\n",
    "vectorizer = TfidfVectorizer(stop_words = 'english', max_df = 0.25, min_df = 5)\n",
    "vectorized_array = vectorizer.fit_transform(clean_df['Measure Description']).toarray()\n",
    "names_list = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add new right columns\n",
    "df = pd.DataFrame(vectorized_array.tolist()) # Coerce array into dataframe\n",
    "\n",
    "columns_renamed = {}                         # Create renamed column dictionary\n",
    "for i in enumerate(names_list):\n",
    "    columns_renamed[i[0]] = i[1]\n",
    "cleanup = df.rename(columns = columns_renamed) # 0, 1, ..., 51 -> ability, activities, ..., worsened\n",
    "\n",
    "cleaned_df2 = clean_df.merge(cleanup,         # Inner Join Tfidf with cleaned_df on index\n",
    "                              left_index=True, \n",
    "                              right_index=True, \n",
    "                              how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Move from 100-0 to 1-0\n",
    "cleaned_df2['Continuous Score'] = cleaned_df2['Four Quarter Average Score'].copy()/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select key columns for this model\n",
    "names_list.extend(['Continuous Score'])\n",
    "dataset2 = cleaned_df2[names_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling No.2 <a id = 'modeling2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split testing, validating, and training\n",
    "dataset2_X, dataset2_y = dataset2.iloc[:,:-1], dataset2.iloc[:,-1]\n",
    "X_train2, X_test2, y_train2, y_test2 = m_sel.train_test_split(dataset2_X, dataset2_y, \n",
    "                                                    test_size=0.33, \n",
    "                                                    random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression()\n"
     ]
    }
   ],
   "source": [
    "# Create 10 folds of cross validation and use logit regression\n",
    "model2 = LinearRegression()\n",
    "cv = m_sel.KFold(n_splits=10, random_state=444, shuffle=True)\n",
    "print(model2.fit(X_train2, y_train2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the 10 fold average metrics\n",
    "thenames2 = ['Accuracy','Mean Absolute Error','Brier Score']\n",
    "scorings2 = ['r2','neg_mean_absolute_error','neg_mean_squared_error']\n",
    "scores2 = {}\n",
    "\n",
    "for i in enumerate(thenames2):\n",
    "    scores2[thenames2[i[0]]] = m_sel.cross_val_score(model2, \n",
    "                                                   X_train2, y_train2,\n",
    "                                                   cv=cv, scoring=scorings2[i[0]])\n",
    "    scores2[thenames2[i[0]]] = np.absolute(round(np.mean(scores2[thenames2[i[0]]]),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Accuracy': 0.0, 'Mean Absolute Error': 0.327, 'Brier Score': 0.135}\n"
     ]
    }
   ],
   "source": [
    "print(scores2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling No.3 <a id='modeling3'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split testing, validating, and training\n",
    "dataset3_X, dataset3_y = dataset2.iloc[:,:-1], dataset2.iloc[:,-1]\n",
    "X_train3, X_test3, y_train3, y_test3 = m_sel.train_test_split(dataset3_X, dataset3_y, \n",
    "                                                    test_size=0.33, \n",
    "                                                    random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor()\n"
     ]
    }
   ],
   "source": [
    "# Create 10 folds of cross validation and use logit regression\n",
    "model3 = RandomForestRegressor()\n",
    "cv = m_sel.KFold(n_splits=10, random_state=444, shuffle=True)\n",
    "print(model3.fit(X_train3, y_train3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the 10 fold average metrics\n",
    "thenames3 = ['Accuracy','Mean Absolute Error','Brier Score']\n",
    "scorings3 = ['r2','neg_mean_absolute_error','neg_mean_squared_error']\n",
    "scores3 = {}\n",
    "\n",
    "for i in enumerate(thenames2):\n",
    "    scores3[thenames2[i[0]]] = m_sel.cross_val_score(model3, \n",
    "                                                   X_train3, y_train3,\n",
    "                                                   cv=cv, scoring=scorings3[i[0]])\n",
    "    scores3[thenames2[i[0]]] = np.absolute(round(np.mean(scores3[thenames3[i[0]]]),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Accuracy': 0.0, 'Mean Absolute Error': 0.327, 'Brier Score': 0.135}\n"
     ]
    }
   ],
   "source": [
    "print(scores3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
